{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AUTHOR: RAIHAN SALMAN BAEHAQI (1103220180)**"
      ],
      "metadata": {
        "id": "urE1iqlkxpBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PART I**  \n",
        "\n",
        "**The Fundamentals of Machine Learning**  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iCm6RKYayWEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHAPTER 2 - End-to-End Machine Learning Project**  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qk19TySkyus-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Presents a comprehensive end-to-end machine learning project using the California Housing Prices dataset. This chapter demonstrates the complete workflow from data acquisition to model deployment using a practical real estate pricing prediction problem. The chapter guides readers through eight main steps: looking at the big picture, getting the data, discovering and visualizing data, preparing data for ML algorithms, selecting and training a model, fine-tuning the model, presenting the solution, and launching/monitoring the system.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "5jjYnTZFzI2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working with Real Data**  \n",
        "\n",
        "The chapter uses the California Housing Prices dataset from StatLib repository based on 1990 census data. Recommended data sources include UC Irvine ML Repository, Kaggle, AWS datasets, Data Portals, OpenDataMonitor, and Quandl.\n",
        "\n",
        "![Figure2-1.jpg](./02.Chapter-02/Figure2-1.jpg)  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uegosBrF5I0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Look at the Big Picture**"
      ],
      "metadata": {
        "id": "kH-eyK9Z5saq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frame the Problem**  \n",
        "\n",
        "The business objective is building a model to predict median housing prices in California districts for a real estate investment ML pipeline. The model output feeds into a downstream system that determines investment worthiness.\n",
        "\n",
        "![Figure2-2.jpg](./02.Chapter-02/Figure2-2.jpg)\n",
        "\n",
        "Pipelines are sequences of data processing components running asynchronously, where each component pulls data, processes it, and outputs results to another data store. This architecture provides simplicity, allows different teams to focus on different components, and creates robustness, though broken components can go unnoticed without proper monitoring.  \n",
        "\n",
        "The problem is classified as:\n",
        "* Supervised learning (labeled training examples with expected outputs)​\n",
        "* Regression task (predicting a continuous value)​\n",
        "* Multiple regression (uses multiple features)​\n",
        "* Univariate regression (predicting single value per district)​\n",
        "* Batch learning (no continuous data flow, data fits in memory)"
      ],
      "metadata": {
        "id": "vuCaDFmP6KA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select a Performance Measure**  \n",
        "\n",
        "Root Mean Square Error (RMSE) is the typical regression performance measure, providing error magnitude with higher weight for large errors:  \n",
        "\n",
        "Equation 2-1. Root Mean Square Error (RMSE)  \n",
        "![Eq2-1.jpg](./02.Chapter-02/Eq2-1.jpg)\n",
        "\n",
        "Where:\n",
        "* m = number of instances in the dataset​  \n",
        "* x<sup>(i)</sup> = vector of feature values for the ith instance​\n",
        "* y<sup>(i)</sup> = label (desired output) for that instance​\n",
        "* X = matrix containing all feature values of all instances​\n",
        "* h = prediction function (hypothesis)  \n",
        "\n",
        "<br> Mean Absolute Error (MAE) is preferred when dealing with many outliers:  \n",
        "\n",
        "Equation 2-2. Mean absolute error (MAE)  \n",
        "![Eq2-2.jpg](./02.Chapter-02/Eq2-2.jpg)  \n",
        "\n",
        "Distance Measures and Norms:\n",
        "* Euclidean norm (ℓ2): Root of sum of squares (RMSE)​  \n",
        "* Manhattan norm (ℓ1): Sum of absolutes (MAE)  ​  \n",
        "* ℓk norm: ||v||<sub>k</sub> = (|v<sub>0</sub>|<sup>k</sup> + |v<sub>1</sub>|<sup>k</sup> + ... + |v<sub>n</sub>|<sup>k</sup>)<sup>1/k</sup>\n",
        "* ℓ0: Number of nonzero elements​  \n",
        "* ℓ∞: Maximum absolute value  \n",
        "\n",
        "Higher norm indices focus more on large values and neglect small ones, making RMSE more sensitive to outliers than MAE."
      ],
      "metadata": {
        "id": "K2_hd7GD6sVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the Assumptions**\n",
        "\n",
        "Verify all assumptions early to catch serious issues. For example, confirm that downstream systems need actual prices rather than categories to avoid framing the problem incorrectly.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "utUL0QgT_L1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the Data**"
      ],
      "metadata": {
        "id": "R0xvteDg_aFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the Workspace**  \n",
        "\n",
        "Install Python 3 and required modules:"
      ],
      "metadata": {
        "id": "UtXpvrQO_iiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ export ML_PATH=\"$HOME/ml\"\n",
        "$ mkdir -p $ML_PATH"
      ],
      "metadata": {
        "id": "Dwg80o_8_n3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check pip installation:"
      ],
      "metadata": {
        "id": "den39w_E_qeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip --version\n",
        "pip 19.3.1 from [...]/lib/python3.7/site-packages/pip (python 3.7)"
      ],
      "metadata": {
        "id": "HuASqb8I_tEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upgrade pip:"
      ],
      "metadata": {
        "id": "fP-18czi_vU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip install --user -U pip"
      ],
      "metadata": {
        "id": "BEFjZhI8_xxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Isolated Environment**  \n",
        "\n",
        "Install and create virtualenv for isolated project environments:"
      ],
      "metadata": {
        "id": "0SqJPO8G_zmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip install --user -U virtualenv\n",
        "$ cd $ML_PATH\n",
        "$ python3 -m virtualenv my_env\n",
        "$ source my_env/bin/activate  # on Linux/macOS\n",
        "$ .\\my_env\\Scripts\\activate   # on Windows"
      ],
      "metadata": {
        "id": "mSqk9TrjAF00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages:"
      ],
      "metadata": {
        "id": "gECY3hPmAG3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip install -U jupyter matplotlib numpy pandas scipy scikit-learn"
      ],
      "metadata": {
        "id": "jp1L8nkqAJi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Register virtualenv to Jupyter:"
      ],
      "metadata": {
        "id": "85W-4HsXAL0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m ipykernel install --user --name=python3"
      ],
      "metadata": {
        "id": "07VWrQk_AOvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Jupyter server:"
      ],
      "metadata": {
        "id": "9HjK3_XMAQ75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ jupyter notebook"
      ],
      "metadata": {
        "id": "TlZQWavCAU9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-3.jpg](./02.Chapter-02/Figure2-3.jpg)  \n",
        "\n",
        "![Figure2-4.jpg](./02.Chapter-02/Figure2-4.jpg)"
      ],
      "metadata": {
        "id": "H14iCvVVAXQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the Data**  \n",
        "\n",
        "Create an automated function to fetch data:"
      ],
      "metadata": {
        "id": "W72g9olTAlta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "metadata": {
        "id": "IQZtg6miAyOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data with pandas:"
      ],
      "metadata": {
        "id": "fuDxrKOgA0yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n"
      ],
      "metadata": {
        "id": "WoO61qy9A3kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take a Quick Look at the Data Structure**\n",
        "\n",
        "View the first five rows:"
      ],
      "metadata": {
        "id": "7nxeuhvxA5KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.head()"
      ],
      "metadata": {
        "id": "eWXg9er4BCbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-5.jpg](./02.Chapter-02/Figure2-5.jpg)  \n",
        "\n",
        "The dataset contains 10 attributes: longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, households, median_income, median_house_value, and ocean_proximity.\n",
        "\n",
        "Get dataset information:"
      ],
      "metadata": {
        "id": "R6o-Oyo8BEN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info()"
      ],
      "metadata": {
        "id": "-j6gjkasBQcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-6.jpg](./02.Chapter-02/Figure2-6.jpg)  \n",
        "\n",
        "All attributes are numerical except ocean_proximity (object/text). Check categorical values:"
      ],
      "metadata": {
        "id": "JRy0R2PRBSGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> housing[\"ocean_proximity\"].value_counts()\n",
        "<1H OCEAN     9136\n",
        "INLAND        6551\n",
        "NEAR OCEAN    2658\n",
        "NEAR BAY      2290\n",
        "ISLAND           5\n",
        "Name: ocean_proximity, dtype: int64"
      ],
      "metadata": {
        "id": "S3yo4uHbBZzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View statistical summary:"
      ],
      "metadata": {
        "id": "aXD6wLPSBcx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.describe()"
      ],
      "metadata": {
        "id": "2nqgDFWiBhAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-7.jpg](./02.Chapter-02/Figure2-7.jpg)  \n",
        "\n",
        "Create histograms for all numerical attributes:"
      ],
      "metadata": {
        "id": "FfD4-pWHBj6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tnOdWv07Bsgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-8.jpg](./02.Chapter-02/Figure2-8.jpg)\n",
        "\n",
        "Key observations from histograms:\n",
        "1. Median income is scaled and capped (0.5 to 15), representing roughly tens of thousands of dollars​\n",
        "2. Housing median age and median house value are capped, potentially problematic for the target attribute​\n",
        "3. Attributes have very different scales requiring feature scaling​\n",
        "4. Many histograms are tail-heavy, extending farther right than left, requiring transformation for bell-shaped distributions"
      ],
      "metadata": {
        "id": "jJQhm8RQB0-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Test Set**\n",
        "\n",
        "Simple random sampling function:"
      ],
      "metadata": {
        "id": "PHBwtLptCGOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]\n",
        "\n",
        ">>> train_set, test_set = split_train_test(housing, 0.2)\n",
        ">>> len(train_set)\n",
        "16512\n",
        ">>> len(test_set)\n",
        "4128"
      ],
      "metadata": {
        "id": "r6MD6TrECLDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For stable splits across updates, use identifier-based hashing:"
      ],
      "metadata": {
        "id": "XPykZZ5ICNfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "housing_with_id = housing.reset_index()\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ],
      "metadata": {
        "id": "aRw4kvG9CP1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or create stable ID from latitude/longitude:"
      ],
      "metadata": {
        "id": "ULYbwF02CSAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ],
      "metadata": {
        "id": "HYKigrzPCUir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Scikit-Learn's train_test_split:"
      ],
      "metadata": {
        "id": "C8_x7fxxCZd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xspFLcJ0ChzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratified Sampling ensures representative test sets. Create income categories based on median income importance:"
      ],
      "metadata": {
        "id": "NfEKIeSfCjod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])\n",
        "housing[\"income_cat\"].hist()"
      ],
      "metadata": {
        "id": "xgW7y0FhCl97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-9.jpg](./02.Chapter-02/Figure2-9.jpg)  \n",
        "\n",
        "Perform stratified sampling:"
      ],
      "metadata": {
        "id": "GCqutrfsCnrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "metadata": {
        "id": "mS53jkGNC12G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify stratification worked:"
      ],
      "metadata": {
        "id": "PiJYwUiAC3yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)\n",
        "3    0.350533\n",
        "2    0.318798\n",
        "4    0.176357\n",
        "5    0.114583\n",
        "1    0.039729\n",
        "Name: income_cat, dtype: float64"
      ],
      "metadata": {
        "id": "T0YHW4ekC6wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-10.jpg](./02.Chapter-02/Figure2-10.jpg)  \n",
        "\n",
        "Remove income_cat to restore original data:"
      ],
      "metadata": {
        "id": "bQjvNARjC8fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "jOztwX5dDHMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---  \n",
        "\n",
        "**Discover and Visualize the Data to Gain Insights**  \n",
        "\n",
        "Create a copy of training set for exploration:"
      ],
      "metadata": {
        "id": "Tt4h8AUSDKlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = strat_train_set.copy()"
      ],
      "metadata": {
        "id": "Uf4KgSMIDTz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing Geographical Data**  \n",
        "\n",
        "Basic scatterplot:"
      ],
      "metadata": {
        "id": "3pUenJB3DVXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ],
      "metadata": {
        "id": "_0o1vhh9Dblr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-11.jpg](./02.Chapter-02/Figure2-11.jpg)  \n",
        "\n",
        "Enhanced visualization with transparency:"
      ],
      "metadata": {
        "id": "5t0RDxRBDdkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ],
      "metadata": {
        "id": "OkTZzNIPDjnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-12.jpg](./02.Chapter-02/Figure2-12.jpg)  \n",
        "\n",
        "Advanced visualization with price and population:"
      ],
      "metadata": {
        "id": "3u4lHsuqDl5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "    sharex=False)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "De8CxFNzD0PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-13.jpg](./02.Chapter-02/Figure2-13.jpg)  "
      ],
      "metadata": {
        "id": "-JyLvcryD2qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looking for Correlations**  \n",
        "\n",
        "Compute correlation matrix:"
      ],
      "metadata": {
        "id": "2_Z9j48MD9rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = housing.corr()\n",
        ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
        "median_house_value    1.000000\n",
        "median_income         0.687160\n",
        "total_rooms           0.135097\n",
        "housing_median_age    0.114110\n",
        "households            0.064506\n",
        "total_bedrooms        0.047689\n",
        "population           -0.026920\n",
        "longitude            -0.047432\n",
        "latitude             -0.142724\n",
        "Name: median_house_value, dtype: float64"
      ],
      "metadata": {
        "id": "WDi2xXnvEGXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation coefficient ranges from -1 to +1, measuring only linear relationships. Median income shows strongest positive correlation (0.687) with median house value.  \n",
        "\n",
        "Use scatter matrix to visualize correlations:"
      ],
      "metadata": {
        "id": "o7LQyfmrEIDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "metadata": {
        "id": "K_NSfVNyEMmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-14.jpg](./02.Chapter-02/Figure2-14.jpg)\n",
        "\n",
        "Focus on median_income correlation:"
      ],
      "metadata": {
        "id": "sq7GWvytEOJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)"
      ],
      "metadata": {
        "id": "Tg_9c0DuEUuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure2-15.jpg](./02.Chapter-02/Figure2-15.jpg)  "
      ],
      "metadata": {
        "id": "7zxreiHmEWQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimenting with Attribute Combinations**  \n",
        "\n",
        "Create new combined attributes:"
      ],
      "metadata": {
        "id": "oUIklrv0EfzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
        "median_house_value          1.000000\n",
        "median_income               0.687160\n",
        "rooms_per_household         0.146285\n",
        "total_rooms                 0.135097\n",
        "housing_median_age          0.114110\n",
        "households                  0.064506\n",
        "total_bedrooms              0.047689\n",
        "population_per_household   -0.021985\n",
        "population                 -0.026920\n",
        "longitude                  -0.047432\n",
        "latitude                   -0.142724\n",
        "bedrooms_per_room          -0.259984\n",
        "Name: median_house_value, dtype: float64"
      ],
      "metadata": {
        "id": "XffG5d7kEkol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new bedrooms_per_room attribute shows stronger negative correlation (-0.260) than total_bedrooms.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WyY-S9BrEmjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the Data for Machine Learning Algorithms**  \n",
        "\n",
        "Revert to clean training set and separate predictors from labels:"
      ],
      "metadata": {
        "id": "4RjqtQzlEtHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "metadata": {
        "id": "QQeKGOXnE3qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**  \n",
        "\n",
        "Handle missing values (total_bedrooms has 207 missing):  \n",
        "\n",
        "Option 1: Drop districts with missing values"
      ],
      "metadata": {
        "id": "bqjBroFcE5Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.dropna(subset=[\"total_bedrooms\"])"
      ],
      "metadata": {
        "id": "wVO_DvX8FAEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 2: Drop the whole attribute"
      ],
      "metadata": {
        "id": "o5cI2n6EFCDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.drop(\"total_bedrooms\", axis=1)"
      ],
      "metadata": {
        "id": "p7nU91c1FEFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 3: Set missing values to median (zero, mean, etc.)"
      ],
      "metadata": {
        "id": "fGyf93tuFFb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
      ],
      "metadata": {
        "id": "Y6M-s80mFIHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Scikit-Learn's SimpleImputer:"
      ],
      "metadata": {
        "id": "aPB8MeK3FJcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "imputer.fit(housing_num)\n",
        "\n",
        ">>> imputer.statistics_\n",
        "array([   -118.51  ,     34.26  ,     29.    ,   2119.5   ,    433.    ,\n",
        "          1164.    ,    408.    ,      3.5409])\n",
        ">>> housing_num.median().values\n",
        "array([   -118.51  ,     34.26  ,     29.    ,   2119.5   ,    433.    ,\n",
        "          1164.    ,    408.    ,      3.5409])\n",
        "\n",
        "X = imputer.transform(housing_num)\n",
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)"
      ],
      "metadata": {
        "id": "Cqh3qkNDFLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn Design Principles:\n",
        "* Consistency: Estimators (fit), Transformers (transform), Predictors (predict)​\n",
        "* Inspection: Hyperparameters accessible as public instance variables (imputer.strategy)​\n",
        "* Nonproliferation of classes: Datasets are NumPy arrays or SciPy sparse matrices​\n",
        "* Composition: Reusable building blocks (pipelines)​\n",
        "* Sensible defaults: Reasonable default parameter values"
      ],
      "metadata": {
        "id": "dT6RePHpFRUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Text and Categorical Attributes**  \n",
        "\n",
        "Most ML algorithms prefer numbers. Use OrdinalEncoder:"
      ],
      "metadata": {
        "id": "ezmszluHFjG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat = housing[[\"ocean_proximity\"]]\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "\n",
        ">>> housing_cat_encoded[:10]\n",
        "array([[0.],\n",
        "       [0.],\n",
        "       [4.],\n",
        "       [1.],\n",
        "       [0.],\n",
        "       [1.],\n",
        "       [0.],\n",
        "       [1.],\n",
        "       [0.],\n",
        "       [0.]])\n",
        "\n",
        ">>> ordinal_encoder.categories_\n",
        "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
        "      dtype=object)]"
      ],
      "metadata": {
        "id": "qaC0klMEFnhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For non-ordinal categories, use one-hot encoding:"
      ],
      "metadata": {
        "id": "qdJM-aQ9FrbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "\n",
        ">>> housing_cat_1hot\n",
        "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
        "    with 16512 stored elements in Compressed Sparse Row format>\n",
        "\n",
        ">>> housing_cat_1hot.toarray()\n",
        "array([[1., 0., 0., 0., 0.],\n",
        "       [1., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 1.],\n",
        "       ...,\n",
        "       [0., 1., 0., 0., 0.],\n",
        "       [1., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 1., 0.]])\n",
        "\n",
        ">>> cat_encoder.categories_\n",
        "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
        "      dtype=object)]"
      ],
      "metadata": {
        "id": "Qln5j6L6Ftao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding creates binary attributes (dummy variables) to avoid implying similarity between unrelated categories."
      ],
      "metadata": {
        "id": "BLPfOrr-Fvmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Transformers**  \n",
        "\n",
        "Create transformers for custom cleanup operations:"
      ],
      "metadata": {
        "id": "2WAFebiMFzP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self  # nothing else to do\n",
        "    def transform(self, X):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household,\n",
        "                         bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "metadata": {
        "id": "_o9aRzWsF4dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding hyperparameters (add_bedrooms_per_room) helps find good combinations through automatic hyperparameter tuning."
      ],
      "metadata": {
        "id": "MgpoTe_NF5vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**  \n",
        "\n",
        "ML algorithms don't perform well when numerical attributes have very different scales.  \n",
        "\n",
        "Min-max scaling (normalization) shifts values to 0-1 range using MinMaxScaler:"
      ],
      "metadata": {
        "id": "uFxEzTtHF-TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "1X_m2bc8GEvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization subtracts mean and divides by standard deviation, resulting in zero mean and unit variance using StandardScaler:"
      ],
      "metadata": {
        "id": "8r2an-9JGGCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Ld1PC4p4GH4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization is less affected by outliers and doesn't bound values to a specific range. Scaling applies to training data only; fit_transform() on training, transform() on test/new data."
      ],
      "metadata": {
        "id": "7iHE6b8BGKty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation Pipelines**  \n",
        "\n",
        "Chain transformations using Pipeline:"
      ],
      "metadata": {
        "id": "XNXSYxjoGNhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "metadata": {
        "id": "2kzhRQZWGRxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipelines execute transformers sequentially, using fit_transform() for all except the last step. All names except the last must be transformers.  \n",
        "\n",
        "Handle categorical and numerical columns together with ColumnTransformer:"
      ],
      "metadata": {
        "id": "hemfRBrAGTjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "metadata": {
        "id": "xKG7Oir1GYji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ColumnTransformer applies appropriate transformations to each column subset, concatenating outputs.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JZX8JjcuGb88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select a Model and Train It**"
      ],
      "metadata": {
        "id": "JojRMqd5GiJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Evaluating on the Training Set**  \n",
        "\n",
        "Train Linear Regression:"
      ],
      "metadata": {
        "id": "mvzueuS1GlCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        ">>> some_data = housing.iloc[:5]\n",
        ">>> some_labels = housing_labels.iloc[:5]\n",
        ">>> some_data_prepared = full_pipeline.transform(some_data)\n",
        ">>> print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        "Predictions: [ 210644.60459286  317768.80697211  210956.43331178   59218.98886849\n",
        "  189747.55849879]\n",
        ">>> print(\"Labels:\", list(some_labels))\n",
        "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]"
      ],
      "metadata": {
        "id": "c_41bc3DGow-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure RMSE on training set:"
      ],
      "metadata": {
        "id": "GOOGCt8wGqN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        ">>> lin_rmse\n",
        "68628.19819848922"
      ],
      "metadata": {
        "id": "Mxo4LcVCGsRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE of $68,628 indicates underfitting (high bias) - features don't provide enough information or the model isn't powerful enough.  \n",
        "\n",
        "Solutions for underfitting:\n",
        "* Select more powerful model​\n",
        "* Feed better features to algorithm​\n",
        "* Reduce constraints (regularization)  \n",
        "\n",
        "Train Decision Tree Regressor:"
      ],
      "metadata": {
        "id": "Os6CP1KgGvHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        ">>> tree_rmse\n",
        "0.0"
      ],
      "metadata": {
        "id": "1ulzlxVxG_b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero error indicates severe overfitting - the model memorized training data."
      ],
      "metadata": {
        "id": "huuLhbOtHBFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better Evaluation Using Cross-Validation**\n",
        "\n",
        "K-fold cross-validation randomly splits training set into K folds, trains and evaluates K times:"
      ],
      "metadata": {
        "id": "cjQXG-GlHDzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        ">>> display_scores(tree_rmse_scores)\n",
        "Scores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n",
        " 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n",
        " 75366.87952553 71231.65726027]\n",
        "Mean: 71407.68766037929\n",
        "Standard deviation: 2439.4345041191004"
      ],
      "metadata": {
        "id": "RvEZ5oKfHJs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree actually performs worse than Linear Regression when properly evaluated.  \n",
        "\n",
        "Cross-validate Linear Regression:"
      ],
      "metadata": {
        "id": "c0zfwL-1HKsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                                  scoring=\"neg_mean_squared_error\", cv=10)\n",
        ">>> lin_rmse_scores = np.sqrt(-lin_scores)\n",
        ">>> display_scores(lin_rmse_scores)\n",
        "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
        " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
        " 71552.91566558 67665.10082067]\n",
        "Mean: 69052.46136345083\n",
        "Standard deviation: 2731.674001798348"
      ],
      "metadata": {
        "id": "VXpaA7MQHPgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Random Forest Regressor:"
      ],
      "metadata": {
        "id": "xFlzEeIoHSTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        ">>> forest_rmse\n",
        "18603.515021376355\n",
        "\n",
        ">>> forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                     scoring=\"neg_mean_squared_error\", cv=10)\n",
        ">>> forest_rmse_scores = np.sqrt(-forest_scores)\n",
        ">>> display_scores(forest_rmse_scores)\n",
        "Scores: [49519.80364233 47461.9115823  50029.02762854 52325.28068953\n",
        " 49308.39426421 53446.37892622 48634.8036574  47585.73832311\n",
        " 53490.10699751 50021.5852922 ]\n",
        "Mean: 50182.303100336096\n",
        "Standard deviation: 2097.0810550985693"
      ],
      "metadata": {
        "id": "T7_v0AdmHTPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest performs much better (training RMSE 18,604, CV mean 50,182) but shows overfitting. Save models for later comparison:"
      ],
      "metadata": {
        "id": "tRuyR11mHVaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(my_model, \"my_model.pkl\")\n",
        "my_model_loaded = joblib.load(\"my_model.pkl\")"
      ],
      "metadata": {
        "id": "W5KNm0bQHXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---  \n",
        "\n",
        "**Fine-Tune Your Model**"
      ],
      "metadata": {
        "id": "JYsLzlqhHYo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search**  \n",
        "\n",
        "Systematically explore hyperparameter combinations:"
      ],
      "metadata": {
        "id": "q-bejyDuHe-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # try 12 (3×4) combinations of hyperparameters\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # then try 6 (2×3) combinations with bootstrap set as False\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "S8FQa2ASHjnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trains across (12+6) × 5 = 90 different models."
      ],
      "metadata": {
        "id": "GXIPBwIrHnYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> grid_search.best_params_\n",
        "{'max_features': 8, 'n_estimators': 30}\n",
        "\n",
        ">>> grid_search.best_estimator_\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features=8, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=1, min_samples_split=2,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=30,\n",
        "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
        "                      warm_start=False)"
      ],
      "metadata": {
        "id": "lFVdQhMZHp7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access evaluation scores:"
      ],
      "metadata": {
        "id": "20zlHLZYHsUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> cvres = grid_search.cv_results_\n",
        ">>> for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "...     print(np.sqrt(-mean_score), params)\n",
        "...\n",
        "63669.11631261028 {'max_features': 2, 'n_estimators': 3}\n",
        "55627.099719926795 {'max_features': 2, 'n_estimators': 10}\n",
        "53384.57275149205 {'max_features': 2, 'n_estimators': 30}\n",
        "60965.950449450494 {'max_features': 4, 'n_estimators': 3}\n",
        "52741.04704299915 {'max_features': 4, 'n_estimators': 10}\n",
        "50377.40461678399 {'max_features': 4, 'n_estimators': 30}\n",
        "58663.93866579625 {'max_features': 6, 'n_estimators': 3}\n",
        "52006.19873526564 {'max_features': 6, 'n_estimators': 10}\n",
        "50146.51167415009 {'max_features': 6, 'n_estimators': 30}\n",
        "57869.25276169646 {'max_features': 8, 'n_estimators': 3}\n",
        "51711.127883959234 {'max_features': 8, 'n_estimators': 10}\n",
        "49682.273345071546 {'max_features': 8, 'n_estimators': 30}\n",
        "62895.06951262424 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
        "54658.176157539405 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
        "59470.40652318466 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
        "52724.9822587892 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
        "57490.5691951261 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
        "51009.495668875716 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}"
      ],
      "metadata": {
        "id": "blib1qZ6Ht6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best combination: max_features=8, n_estimators=30, achieving RMSE of 49,682."
      ],
      "metadata": {
        "id": "gnD8V3XnHxRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Randomized Search**  \n",
        "\n",
        "For large hyperparameter spaces, RandomizedSearchCV evaluates random combinations, providing better coverage with controlled iterations. Useful when the hyperparameter search space is large."
      ],
      "metadata": {
        "id": "fVbjQoZbH0dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble Methods**  \n",
        "\n",
        "Combine best-performing models for better results (e.g., Random Forest already ensembles Decision Trees)."
      ],
      "metadata": {
        "id": "7WlK1DjBH56i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze the Best Models and Their Errors**  \n",
        "\n",
        "Examine feature importances:"
      ],
      "metadata": {
        "id": "bpQZm7RKH_gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> feature_importances = grid_search.best_estimator_.feature_importances_\n",
        ">>> feature_importances\n",
        "array([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02,\n",
        "       1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01,\n",
        "       5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,\n",
        "       1.64780994e-01, 6.02803867e-05, 1.96041560e-03, 2.85647464e-03])\n",
        "\n",
        ">>> extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        ">>> cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
        ">>> cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        ">>> attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        ">>> sorted(zip(feature_importances, attributes), reverse=True)\n",
        "[(0.3661589806181342, 'median_income'),\n",
        " (0.1647809935615905, 'INLAND'),\n",
        " (0.10879295677551573, 'pop_per_hhold'),\n",
        " (0.07334423551601243, 'longitude'),\n",
        " (0.06290907048262032, 'latitude'),\n",
        " (0.056419179181954014, 'rooms_per_hhold'),\n",
        " (0.053351077347675815, 'bedrooms_per_room'),\n",
        " (0.04114379847872964, 'housing_median_age'),\n",
        " (0.014874280890402769, 'population'),\n",
        " (0.014672685420543239, 'total_rooms'),\n",
        " (0.014257599323407808, 'households'),\n",
        " (0.014106483453584104, 'total_bedrooms'),\n",
        " (0.010311488326303788, '<1H OCEAN'),\n",
        " (0.0028564746373201584, 'NEAR OCEAN'),\n",
        " (0.0019604155994780706, 'NEAR BAY'),\n",
        " (6.0280386727366e-05, 'ISLAND')]"
      ],
      "metadata": {
        "id": "1eJwXzfoIGbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This information helps decide which features to drop. For example, only one ocean_proximity category (INLAND) is really useful."
      ],
      "metadata": {
        "id": "DnNshR2ZILZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Your System on the Test Set**  \n",
        "\n",
        "Final evaluation on test set:"
      ],
      "metadata": {
        "id": "pPwCzIxIIReV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        ">>> final_rmse\n",
        "47730.22690385927"
      ],
      "metadata": {
        "id": "3OMB2fQdIVlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute 95% confidence interval:"
      ],
      "metadata": {
        "id": "MHaOoS-jIXMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "confidence = 0.95\n",
        "squared_errors = (final_predictions - y_test) ** 2\n",
        ">>> np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
        "                              loc=squared_errors.mean(),\n",
        "                              scale=stats.sem(squared_errors)))\n",
        "array([45685.10470776, 49691.25001878])"
      ],
      "metadata": {
        "id": "pm3XDl4-IZIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generalization error is estimated between $45,685 and 49,691 with 95% confidence.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jW1apwEnIbNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Launch, Monitor, and Maintain Your System**  \n",
        "\n",
        "Present Your Solution\n",
        "Document findings, highlight what worked and what didn't, list assumptions and system limitations, and create clear visualizations and presentations.​\n",
        "\n",
        "Launch\n",
        "Get solution ready for production:​\n",
        "* Plug into production input data sources​\n",
        "* Write unit tests​\n",
        "* Write monitoring code for live performance and trigger alerts on drops​\n",
        "\n",
        "Deployment options:\n",
        "* Save trained model and load in production environment​\n",
        "* Wrap model in web service (REST API)​\n",
        "* Deploy to cloud (Google Cloud AI Platform provides simple API for loading and deploying models)​\n",
        "\n",
        "Monitor and Maintain\n",
        "Models degrade over time (\"model rot\") as data evolves. Monitor regularly and retrain on fresh data.​\n",
        "\n",
        "Monitoring strategies:\n",
        "* Sample predictions and evaluate through human raters or downstream system performance​\n",
        "* Monitor input data quality to catch upstream issues​\n",
        "* Train models on regular schedules or when performance drops​\n",
        "* Automate the entire process​\n",
        "\n",
        "Automation best practices:\n",
        "* Collect fresh data regularly and label it​\n",
        "* Write scripts to train and fine-tune models automatically​\n",
        "* Write scripts to evaluate new models against previous ones on updated test sets​\n",
        "* Deploy new models if significantly better than existing ones​\n",
        "* Monitor input quality and alert on degradation​\n",
        "* Keep backups of datasets and models for rollback capability​\n",
        "\n",
        "The chapter concludes by emphasizing that successful ML projects require extensive infrastructure beyond algorithm selection, including robust data pipelines, monitoring systems, human evaluation frameworks, and automated training processes."
      ],
      "metadata": {
        "id": "E34XT5BUIkOs"
      }
    }
  ]
}